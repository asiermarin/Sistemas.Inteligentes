{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema**: Crear un modelo de clasificación que prediga si va a llover o no mañana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data set**: 145.000 observaciones diarias con 24 atributos. Usaremos 23 de ellas para predecir si llueve o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lógica**: Construir un modelo de clasificación que prediga si va a llover o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cargar librerías *numpy* y *pandas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Cargar el dataset weatherAUS.csv usando el método *read_csv* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142188</th>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>1021.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142189</th>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142190</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142191</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142192</th>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142193 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
       "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
       "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
       "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
       "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
       "...            ...      ...      ...      ...       ...          ...   \n",
       "142188  2017-06-20    Uluru      3.5     21.8       0.0          NaN   \n",
       "142189  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
       "142190  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
       "142191  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
       "142192  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  \\\n",
       "0            NaN           W           44.0          W  ...        22.0   \n",
       "1            NaN         WNW           44.0        NNW  ...        25.0   \n",
       "2            NaN         WSW           46.0          W  ...        30.0   \n",
       "3            NaN          NE           24.0         SE  ...        16.0   \n",
       "4            NaN           W           41.0        ENE  ...        33.0   \n",
       "...          ...         ...            ...        ...  ...         ...   \n",
       "142188       NaN           E           31.0        ESE  ...        27.0   \n",
       "142189       NaN           E           31.0         SE  ...        24.0   \n",
       "142190       NaN         NNW           22.0         SE  ...        21.0   \n",
       "142191       NaN           N           37.0         SE  ...        24.0   \n",
       "142192       NaN          SE           28.0        SSE  ...        24.0   \n",
       "\n",
       "        Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
       "0            1007.7       1007.1       8.0       NaN     16.9     21.8   \n",
       "1            1010.6       1007.8       NaN       NaN     17.2     24.3   \n",
       "2            1007.6       1008.7       NaN       2.0     21.0     23.2   \n",
       "3            1017.6       1012.8       NaN       NaN     18.1     26.5   \n",
       "4            1010.8       1006.0       7.0       8.0     17.8     29.7   \n",
       "...             ...          ...       ...       ...      ...      ...   \n",
       "142188       1024.7       1021.2       NaN       NaN      9.4     20.9   \n",
       "142189       1024.6       1020.3       NaN       NaN     10.1     22.4   \n",
       "142190       1023.5       1019.1       NaN       NaN     10.9     24.5   \n",
       "142191       1021.0       1016.8       NaN       NaN     12.5     26.1   \n",
       "142192       1019.4       1016.5       3.0       2.0     15.1     26.0   \n",
       "\n",
       "        RainToday  RISK_MM  RainTomorrow  \n",
       "0              No      0.0            No  \n",
       "1              No      0.0            No  \n",
       "2              No      0.0            No  \n",
       "3              No      1.0            No  \n",
       "4              No      0.2            No  \n",
       "...           ...      ...           ...  \n",
       "142188         No      0.0            No  \n",
       "142189         No      0.0            No  \n",
       "142190         No      0.0            No  \n",
       "142191         No      0.0            No  \n",
       "142192         No      0.0            No  \n",
       "\n",
       "[142193 rows x 24 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherPath = './weatherAUS.csv'\n",
    "pds.read_csv(weatherPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Mostrar el tamaño del data set usando el método *shape* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142193, 24)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pds.read_csv(weatherPath)\n",
    "df10 = pds.read_csv(weatherPath)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Mostrar las 5 primeras líneas del data set usando cualquier método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
      "\n",
      "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
      "0           W           44.0          W  ...        22.0       1007.7   \n",
      "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
      "2         WSW           46.0          W  ...        30.0       1007.6   \n",
      "3          NE           24.0         SE  ...        16.0       1017.6   \n",
      "4           W           41.0        ENE  ...        33.0       1010.8   \n",
      "\n",
      "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
      "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
      "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
      "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
      "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
      "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
      "\n",
      "   RainTomorrow  \n",
      "0            No  \n",
      "1            No  \n",
      "2            No  \n",
      "3            No  \n",
      "4            No  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) En todos los data sets puede haber atributos sesgados, incorrectos, imprecisos etc. Una forma de comprobar qué atributos son es contar los valores y compararlo con el tamaño obtenido en 3). Para ello utilizaremos el método *count* y el método *sort_values* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.sort_values(by='')\n",
    "# print(df.count())\n",
    "# df = data.sort_values(by=count)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Es necesario borrar todas las variables que no sean significativas. Para ello borraremos las siguientes: 'Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date'. RISK_MM denota la cantidad de lluvia prevista al día siguiente y puede dañar nuestro modelo.\n",
    "\n",
    "Para borrar columnas el método *drop* de pandas, y mostraremos a continuación el estado del data set por medio del método *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date  MinTemp  MaxTemp  Rainfall WindGustDir  WindGustSpeed  \\\n",
      "0       2008-12-01     13.4     22.9       0.6           W           44.0   \n",
      "1       2008-12-02      7.4     25.1       0.0         WNW           44.0   \n",
      "2       2008-12-03     12.9     25.7       0.0         WSW           46.0   \n",
      "3       2008-12-04      9.2     28.0       0.0          NE           24.0   \n",
      "4       2008-12-05     17.5     32.3       1.0           W           41.0   \n",
      "...            ...      ...      ...       ...         ...            ...   \n",
      "142188  2017-06-20      3.5     21.8       0.0           E           31.0   \n",
      "142189  2017-06-21      2.8     23.4       0.0           E           31.0   \n",
      "142190  2017-06-22      3.6     25.3       0.0         NNW           22.0   \n",
      "142191  2017-06-23      5.4     26.9       0.0           N           37.0   \n",
      "142192  2017-06-24      7.8     27.0       0.0          SE           28.0   \n",
      "\n",
      "       WindDir9am WindDir3pm  WindSpeed9am  WindSpeed3pm  Humidity9am  \\\n",
      "0               W        WNW          20.0          24.0         71.0   \n",
      "1             NNW        WSW           4.0          22.0         44.0   \n",
      "2               W        WSW          19.0          26.0         38.0   \n",
      "3              SE          E          11.0           9.0         45.0   \n",
      "4             ENE         NW           7.0          20.0         82.0   \n",
      "...           ...        ...           ...           ...          ...   \n",
      "142188        ESE          E          15.0          13.0         59.0   \n",
      "142189         SE        ENE          13.0          11.0         51.0   \n",
      "142190         SE          N          13.0           9.0         56.0   \n",
      "142191         SE        WNW           9.0           9.0         53.0   \n",
      "142192        SSE          N          13.0           7.0         51.0   \n",
      "\n",
      "        Humidity3pm  Pressure9am  Pressure3pm  Temp9am  Temp3pm RainToday  \\\n",
      "0              22.0       1007.7       1007.1     16.9     21.8        No   \n",
      "1              25.0       1010.6       1007.8     17.2     24.3        No   \n",
      "2              30.0       1007.6       1008.7     21.0     23.2        No   \n",
      "3              16.0       1017.6       1012.8     18.1     26.5        No   \n",
      "4              33.0       1010.8       1006.0     17.8     29.7        No   \n",
      "...             ...          ...          ...      ...      ...       ...   \n",
      "142188         27.0       1024.7       1021.2      9.4     20.9        No   \n",
      "142189         24.0       1024.6       1020.3     10.1     22.4        No   \n",
      "142190         21.0       1023.5       1019.1     10.9     24.5        No   \n",
      "142191         24.0       1021.0       1016.8     12.5     26.1        No   \n",
      "142192         24.0       1019.4       1016.5     15.1     26.0        No   \n",
      "\n",
      "       RainTomorrow  \n",
      "0                No  \n",
      "1                No  \n",
      "2                No  \n",
      "3                No  \n",
      "4                No  \n",
      "...             ...  \n",
      "142188           No  \n",
      "142189           No  \n",
      "142190           No  \n",
      "142191           No  \n",
      "142192           No  \n",
      "\n",
      "[142193 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Sunshine', 'Evaporation', 'Cloud3pm', 'Cloud9am', 'Location', 'RISK_MM'])\n",
    "df.shape\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Ahora eliminaremos los datos nulos utilizando para ello el método *dropna* con el parámetro *how='any'* [info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html).\n",
    "  Después, mostraremos el estado del data set por medio del método *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
      "5939    2009-01-01    Cobar     17.9     35.2       0.0         12.0   \n",
      "5940    2009-01-02    Cobar     18.4     28.9       0.0         14.8   \n",
      "5942    2009-01-04    Cobar     19.4     37.6       0.0         10.8   \n",
      "5943    2009-01-05    Cobar     21.9     38.4       0.0         11.4   \n",
      "5944    2009-01-06    Cobar     24.2     41.0       0.0         11.2   \n",
      "...            ...      ...      ...      ...       ...          ...   \n",
      "139108  2017-06-20   Darwin     19.3     33.4       0.0          6.0   \n",
      "139109  2017-06-21   Darwin     21.2     32.6       0.0          7.6   \n",
      "139110  2017-06-22   Darwin     20.7     32.8       0.0          5.6   \n",
      "139111  2017-06-23   Darwin     19.5     31.8       0.0          6.2   \n",
      "139112  2017-06-24   Darwin     20.2     31.7       0.0          5.6   \n",
      "\n",
      "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  \\\n",
      "5939        12.3         SSW           48.0        ENE  ...        13.0   \n",
      "5940        13.0           S           37.0        SSE  ...         8.0   \n",
      "5942        10.6         NNE           46.0        NNE  ...        22.0   \n",
      "5943        12.2         WNW           31.0        WNW  ...        22.0   \n",
      "5944         8.4         WNW           35.0         NW  ...        15.0   \n",
      "...          ...         ...            ...        ...  ...         ...   \n",
      "139108      11.0         ENE           35.0         SE  ...        32.0   \n",
      "139109       8.6           E           37.0         SE  ...        28.0   \n",
      "139110      11.0           E           33.0          E  ...        23.0   \n",
      "139111      10.6         ESE           26.0         SE  ...        58.0   \n",
      "139112      10.7         ENE           30.0        ENE  ...        32.0   \n",
      "\n",
      "        Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
      "5939         1006.3       1004.4       2.0       5.0     26.6     33.4   \n",
      "5940         1012.9       1012.1       1.0       1.0     20.3     27.0   \n",
      "5942         1012.3       1009.2       1.0       6.0     28.7     34.9   \n",
      "5943         1012.7       1009.1       1.0       5.0     29.1     35.6   \n",
      "5944         1010.7       1007.4       1.0       6.0     33.6     37.6   \n",
      "...             ...          ...       ...       ...      ...      ...   \n",
      "139108       1013.9       1010.5       0.0       1.0     24.5     32.3   \n",
      "139109       1014.6       1011.2       7.0       0.0     24.8     32.0   \n",
      "139110       1015.3       1011.8       0.0       0.0     24.8     32.1   \n",
      "139111       1014.9       1010.7       1.0       1.0     24.8     29.2   \n",
      "139112       1013.9       1009.7       6.0       5.0     25.4     31.0   \n",
      "\n",
      "        RainToday  RISK_MM  RainTomorrow  \n",
      "5939           No      0.0            No  \n",
      "5940           No      0.0            No  \n",
      "5942           No      0.0            No  \n",
      "5943           No      0.0            No  \n",
      "5944           No      0.0            No  \n",
      "...           ...      ...           ...  \n",
      "139108         No      0.0            No  \n",
      "139109         No      0.0            No  \n",
      "139110         No      0.0            No  \n",
      "139111         No      0.0            No  \n",
      "139112         No      0.0            No  \n",
      "\n",
      "[56420 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df = data.dropna(how='any')\n",
    "df.shape\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Es interesante comprobar si nuestros datos tienen *outliers* (valroes atípicos), estos son datos que difieren significativamente de otros. Los *outliers* son consecuencia de cálculos erróneos cuando se recopilan los datos.\n",
    "\n",
    "Para esto vamos a emplear el módulo *stats* de la librería SciPy (herramientas y algoritmos matemáticos)\n",
    "\n",
    "    from scipy import stats\n",
    "    \n",
    "A continuación obtenemos el valor absoluto de la desviación típica de todos los datos.\n",
    "\n",
    "    z = np.abs(stats.zscore(df._get_numeric_data()))\n",
    "\n",
    "Un valor de z-score mayor que 3 nos dice que el valor es mucho mayor que el promedio, un valor igual a 0 que está en el promedio.\n",
    "\n",
    "[Standard Normal Distribution](http://www.ltcconline.net/greenl/courses/201/probdist/ctsdis8.jpg)\n",
    "\n",
    "\n",
    "Y utilizamos ese valor para mostrar solo aquellos datos que sean menores que 3 en base a las columnas (axis = 1).\n",
    "\n",
    "    df= df[(z < 3).all(axis=1)]\n",
    "    \n",
    "Por último, mostramos el estado del data set con *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52515, 24)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "z = np.abs(stats.zscore(df._get_numeric_data()))\n",
    "df= df[(z < 3).all(axis=1)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Vamos a emplear 0 y 1 en lugar de  *labels* (etiquetas), en los atributos RainToday y RainTomorrow. Utiliza el método *replace* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
      "5939    2009-01-01    Cobar     17.9     35.2       0.0         12.0   \n",
      "5940    2009-01-02    Cobar     18.4     28.9       0.0         14.8   \n",
      "5942    2009-01-04    Cobar     19.4     37.6       0.0         10.8   \n",
      "5943    2009-01-05    Cobar     21.9     38.4       0.0         11.4   \n",
      "5944    2009-01-06    Cobar     24.2     41.0       0.0         11.2   \n",
      "...            ...      ...      ...      ...       ...          ...   \n",
      "139108  2017-06-20   Darwin     19.3     33.4       0.0          6.0   \n",
      "139109  2017-06-21   Darwin     21.2     32.6       0.0          7.6   \n",
      "139110  2017-06-22   Darwin     20.7     32.8       0.0          5.6   \n",
      "139111  2017-06-23   Darwin     19.5     31.8       0.0          6.2   \n",
      "139112  2017-06-24   Darwin     20.2     31.7       0.0          5.6   \n",
      "\n",
      "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  \\\n",
      "5939        12.3         SSW           48.0        ENE  ...        13.0   \n",
      "5940        13.0           S           37.0        SSE  ...         8.0   \n",
      "5942        10.6         NNE           46.0        NNE  ...        22.0   \n",
      "5943        12.2         WNW           31.0        WNW  ...        22.0   \n",
      "5944         8.4         WNW           35.0         NW  ...        15.0   \n",
      "...          ...         ...            ...        ...  ...         ...   \n",
      "139108      11.0         ENE           35.0         SE  ...        32.0   \n",
      "139109       8.6           E           37.0         SE  ...        28.0   \n",
      "139110      11.0           E           33.0          E  ...        23.0   \n",
      "139111      10.6         ESE           26.0         SE  ...        58.0   \n",
      "139112      10.7         ENE           30.0        ENE  ...        32.0   \n",
      "\n",
      "        Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
      "5939         1006.3       1004.4       2.0       5.0     26.6     33.4   \n",
      "5940         1012.9       1012.1       1.0       1.0     20.3     27.0   \n",
      "5942         1012.3       1009.2       1.0       6.0     28.7     34.9   \n",
      "5943         1012.7       1009.1       1.0       5.0     29.1     35.6   \n",
      "5944         1010.7       1007.4       1.0       6.0     33.6     37.6   \n",
      "...             ...          ...       ...       ...      ...      ...   \n",
      "139108       1013.9       1010.5       0.0       1.0     24.5     32.3   \n",
      "139109       1014.6       1011.2       7.0       0.0     24.8     32.0   \n",
      "139110       1015.3       1011.8       0.0       0.0     24.8     32.1   \n",
      "139111       1014.9       1010.7       1.0       1.0     24.8     29.2   \n",
      "139112       1013.9       1009.7       6.0       5.0     25.4     31.0   \n",
      "\n",
      "        RainToday  RISK_MM  RainTomorrow  \n",
      "5939            0      0.0             1  \n",
      "5940            0      0.0             1  \n",
      "5942            0      0.0             1  \n",
      "5943            0      0.0             1  \n",
      "5944            0      0.0             1  \n",
      "...           ...      ...           ...  \n",
      "139108          0      0.0             1  \n",
      "139109          0      0.0             1  \n",
      "139110          0      0.0             1  \n",
      "139111          0      0.0             1  \n",
      "139112          0      0.0             1  \n",
      "\n",
      "[52515 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"RainToday\"].replace({\"No\": 0}, inplace=True)\n",
    "df[\"RainTomorrow\"].replace({\"No\": 1}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Normalizaremos los datos para que no haya distorsiones entre las diferencias del rango de valores. Esto es necesario cuando las variables tienen diferentes rangos. ¿Por qué? Veamos un ejemplo: \n",
    "\n",
    "Tenemos los atributos edad (0-100) y salario (0-100.000), al hacer una un análisis como una regresión lineal múltiple, el atributo salario tendrá más influencia debido a su mayor valor.\n",
    "\n",
    "Para llevar a cabo la normalización vamos a emplear la función *MinMaxScaler* del módulo *preprocessing* de la librería *sklearn*. (sklearn es como se denota scikit-learn en Python)\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "\n",
    "Mostraremos algunos datos de nuestro data set.\n",
    "(Esta función nos dará error ¿Por qué? ¿Cómo solucionarlo?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-2c783aff7e5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0marreglo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marreglo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   7545\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7546\u001b[0m         )\n\u001b[1;32m-> 7547\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7549\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"DataFrame\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m                     \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m                         \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m    255\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode, check_unknown)\u001b[0m\n\u001b[0;32m    115\u001b[0m             types = sorted(t.__qualname__\n\u001b[0;32m    116\u001b[0m                            for t in set(type(v) for v in values))\n\u001b[1;32m--> 117\u001b[1;33m             raise TypeError(\"Encoders require their input to be uniformly \"\n\u001b[0m\u001b[0;32m    118\u001b[0m                             f\"strings or numbers. Got {types}\")\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input to be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "arreglo = preprocessing.LabelEncoder()\n",
    "df = df10.apply(arreglo.fit_transform)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "\n",
    "df = pds.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "df.iloc[4:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio de datos (Exploratory Data Analysis - EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Vamos a identificar las variables más significativas para predecir nuestra función. Para ello utilizaremos la función *SelectKBest* [info](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) del sklearn. Utilizaremos el método predictivo chi2 para puntuar a cada una de ellas y seleccionaremos solo 3.\n",
    "\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    X = df.loc[:,df.columns!='RainTomorrow']\n",
    "    y = df[['RainTomorrow']]\n",
    "    selector = SelectKBest(chi2, k=3)\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "Y seleccionamos las variables con *get_support*.\n",
    "\n",
    "    print(X.columns[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Rainfall', 'Humidity3pm' y 'RainToday' son las variables más significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo un modelo de aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) En primer lugar, y para simplificar el modelo, vamos a emplear solo 'Humidity3pm' para construirlo. De esta forma tendremos 'Humidity3pm' como entrada y 'RainTomorrow' como salida. \n",
    "Crea una variable 'X' formada únicamente por la columna del *dataframe* 'Humidity3pm' y otra variable 'y' formada por la columna del *dataframe* 'RainTomorrow'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Vamos a construir modelos de clasificación utilizando los distintos algoritmos:\n",
    "- *Logistic regression* (Regresión logística) [info](https://en.wikipedia.org/wiki/Logistic_regression) \n",
    "- *Random Forest* (bosques aleatorios) [info](https://en.wikipedia.org/wiki/Random_forest) \n",
    "- *Decission Tree* (Árbol de decisión) [info](https://en.wikipedia.org/wiki/Decision_tree) \n",
    "- *Support Vector Machine* (Máquinas de vectores de soporte) [info](https://en.wikipedia.org/wiki/Support_vector_machine) \n",
    "\n",
    "\n",
    "No te preocupes si todavía no los conoces, profundizaremos sobre ellos a lo largo del curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1) Logistic regression\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos distintos recursos la librería sklearn. Concretamente necesitaremos el modelo de *logistic regression*, un método para obtener automáticamente los datos de entrenamiento y test, y otro método para obtener la precisión del modelo. \n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dividimos los datos que tenemos en datos de entrenamiento o *training set* (conjunto de datos iniciales utilizados por el modelo para entender el problema y aprender sobre él) y datos de prueba o *test set* (conjunto de datos utilizados para comprobar lo que ha aprendido el modelo después de haber sido entrenado). __Nunca uses los datos de prueba para el entrenamiento o tus resultados estarían comprometidos__. Normalmente se utilzia un 80% de los datos para entrenamiento y un 20% para tests.\n",
    "\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construimos el modelo y lo entrenamos con el *training set*\n",
    "\n",
    "\n",
    "    clf_logreg = LogisticRegression(random_state=0)\n",
    "    clf_logreg.fit(X_train,y_train)\n",
    "\n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluamos el modelo usando el *test set*.\n",
    "\n",
    "    y_pred = clf_logreg.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por último mostramos por pantalla el *score* del modelo en %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crea un modelo Random Forest [info](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    n_estimators=100, max_depth=4,random_state=0\n",
    "\n",
    "(Ignora el *warning*)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.3) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crea un modelo Decision Tree [info](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    random_state=0    \n",
    "    \n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.4) Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un modelo SVM, entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "    from sklearn import svm\n",
    "- Crea un modelo SVM [info](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn import svm\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    kernel='linear'\n",
    "    \n",
    "(Este modelo tarda en torno a 1 minuto en ejecutarse)\n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Ordena de mayor a menor precisión los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) ¿Con qué término en inglés se denota el sobreentrenamiento de un modelo de ML y qué características tiene?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
