{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema**: Crear un modelo de clasificación que prediga si va a llover o no mañana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data set**: 145.000 observaciones diarias con 24 atributos. Usaremos 23 de ellas para predecir si llueve o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lógica**: Construir un modelo de clasificación que prediga si va a llover o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Cargar librerías *numpy* y *pandas*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Cargar el dataset weatherAUS.csv usando el método *read_csv* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142188</th>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1024.7</td>\n",
       "      <td>1021.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142189</th>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142190</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142191</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142192</th>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142193 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
       "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
       "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
       "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
       "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
       "...            ...      ...      ...      ...       ...          ...   \n",
       "142188  2017-06-20    Uluru      3.5     21.8       0.0          NaN   \n",
       "142189  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
       "142190  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
       "142191  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
       "142192  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  \\\n",
       "0            NaN           W           44.0          W  ...        22.0   \n",
       "1            NaN         WNW           44.0        NNW  ...        25.0   \n",
       "2            NaN         WSW           46.0          W  ...        30.0   \n",
       "3            NaN          NE           24.0         SE  ...        16.0   \n",
       "4            NaN           W           41.0        ENE  ...        33.0   \n",
       "...          ...         ...            ...        ...  ...         ...   \n",
       "142188       NaN           E           31.0        ESE  ...        27.0   \n",
       "142189       NaN           E           31.0         SE  ...        24.0   \n",
       "142190       NaN         NNW           22.0         SE  ...        21.0   \n",
       "142191       NaN           N           37.0         SE  ...        24.0   \n",
       "142192       NaN          SE           28.0        SSE  ...        24.0   \n",
       "\n",
       "        Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  \\\n",
       "0            1007.7       1007.1       8.0       NaN     16.9     21.8   \n",
       "1            1010.6       1007.8       NaN       NaN     17.2     24.3   \n",
       "2            1007.6       1008.7       NaN       2.0     21.0     23.2   \n",
       "3            1017.6       1012.8       NaN       NaN     18.1     26.5   \n",
       "4            1010.8       1006.0       7.0       8.0     17.8     29.7   \n",
       "...             ...          ...       ...       ...      ...      ...   \n",
       "142188       1024.7       1021.2       NaN       NaN      9.4     20.9   \n",
       "142189       1024.6       1020.3       NaN       NaN     10.1     22.4   \n",
       "142190       1023.5       1019.1       NaN       NaN     10.9     24.5   \n",
       "142191       1021.0       1016.8       NaN       NaN     12.5     26.1   \n",
       "142192       1019.4       1016.5       3.0       2.0     15.1     26.0   \n",
       "\n",
       "        RainToday  RISK_MM  RainTomorrow  \n",
       "0              No      0.0            No  \n",
       "1              No      0.0            No  \n",
       "2              No      0.0            No  \n",
       "3              No      1.0            No  \n",
       "4              No      0.2            No  \n",
       "...           ...      ...           ...  \n",
       "142188         No      0.0            No  \n",
       "142189         No      0.0            No  \n",
       "142190         No      0.0            No  \n",
       "142191         No      0.0            No  \n",
       "142192         No      0.0            No  \n",
       "\n",
       "[142193 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weatherPath = './weatherAUS.csv'\n",
    "pds.read_csv(weatherPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Mostrar el tamaño del data set usando el método *shape* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(142193, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pds.read_csv(weatherPath)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Mostrar las 5 primeras líneas del data set usando cualquier método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
      "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
      "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
      "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
      "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
      "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
      "\n",
      "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
      "0           W           44.0          W  ...        22.0       1007.7   \n",
      "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
      "2         WSW           46.0          W  ...        30.0       1007.6   \n",
      "3          NE           24.0         SE  ...        16.0       1017.6   \n",
      "4           W           41.0        ENE  ...        33.0       1010.8   \n",
      "\n",
      "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
      "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
      "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
      "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
      "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
      "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
      "\n",
      "   RainTomorrow  \n",
      "0            No  \n",
      "1            No  \n",
      "2            No  \n",
      "3            No  \n",
      "4            No  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-procesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) En todos los data sets puede haber atributos sesgados, incorrectos, imprecisos etc. Una forma de comprobar qué atributos son es contar los valores y compararlo con el tamaño obtenido en 3). Para ello utilizaremos el método *count* y el método *sort_values* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Date             142193\nLocation         142193\nMinTemp          141556\nMaxTemp          141871\nRainfall         140787\nEvaporation       81350\nSunshine          74377\nWindGustDir      132863\nWindGustSpeed    132923\nWindDir9am       132180\nWindDir3pm       138415\nWindSpeed9am     140845\nWindSpeed3pm     139563\nHumidity9am      140419\nHumidity3pm      138583\nPressure9am      128179\nPressure3pm      128212\nCloud9am          88536\nCloud3pm          85099\nTemp9am          141289\nTemp3pm          139467\nRainToday        140787\nRISK_MM          142193\nRainTomorrow     142193\ndtype: int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4a2101e21790>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36msort_values\u001b[1;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[0;32m   5291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5292\u001b[0m             \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5293\u001b[1;33m             \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5295\u001b[0m             \u001b[1;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1558\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1559\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1560\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1562\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: Date             142193\nLocation         142193\nMinTemp          141556\nMaxTemp          141871\nRainfall         140787\nEvaporation       81350\nSunshine          74377\nWindGustDir      132863\nWindGustSpeed    132923\nWindDir9am       132180\nWindDir3pm       138415\nWindSpeed9am     140845\nWindSpeed3pm     139563\nHumidity9am      140419\nHumidity3pm      138583\nPressure9am      128179\nPressure3pm      128212\nCloud9am          88536\nCloud3pm          85099\nTemp9am          141289\nTemp3pm          139467\nRainToday        140787\nRISK_MM          142193\nRainTomorrow     142193\ndtype: int64"
     ]
    }
   ],
   "source": [
    "count = data.count()\n",
    "data.sort_values(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Es necesario borrar todas las variables que no sean significativas. Para ello borraremos las siguientes: 'Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date'. RISK_MM denota la cantidad de lluvia prevista al día siguiente y puede dañar nuestro modelo.\n",
    "\n",
    "Para borrar columnas el método *drop* de pandas, y mostraremos a continuación el estado del data set por medio del método *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Ahora eliminaremos los datos nulos utilizando para ello el método *dropna* con el parámetro *how='any'* [info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html).\n",
    "  Después, mostraremos el estado del data set por medio del método *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Es interesante comprobar si nuestros datos tienen *outliers* (valroes atípicos), estos son datos que difieren significativamente de otros. Los *outliers* son consecuencia de cálculos erróneos cuando se recopilan los datos.\n",
    "\n",
    "Para esto vamos a emplear el módulo *stats* de la librería SciPy (herramientas y algoritmos matemáticos)\n",
    "\n",
    "    from scipy import stats\n",
    "    \n",
    "A continuación obtenemos el valor absoluto de la desviación típica de todos los datos.\n",
    "\n",
    "    z = np.abs(stats.zscore(df._get_numeric_data()))\n",
    "\n",
    "Un valor de z-score mayor que 3 nos dice que el valor es mucho mayor que el promedio, un valor igual a 0 que está en el promedio.\n",
    "\n",
    "[Standard Normal Distribution](http://www.ltcconline.net/greenl/courses/201/probdist/ctsdis8.jpg)\n",
    "\n",
    "\n",
    "Y utilizamos ese valor para mostrar solo aquellos datos que sean menores que 3 en base a las columnas (axis = 1).\n",
    "\n",
    "    df= df[(z < 3).all(axis=1)]\n",
    "    \n",
    "Por último, mostramos el estado del data set con *shape*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Vamos a emplear 0 y 1 en lugar de  *labels* (etiquetas), en los atributos RainToday y RainTomorrow. Utiliza el método *replace* de pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Normalizaremos los datos para que no haya distorsiones entre las diferencias del rango de valores. Esto es necesario cuando las variables tienen diferentes rangos. ¿Por qué? Veamos un ejemplo: \n",
    "\n",
    "Tenemos los atributos edad (0-100) y salario (0-100.000), al hacer una un análisis como una regresión lineal múltiple, el atributo salario tendrá más influencia debido a su mayor valor.\n",
    "\n",
    "Para llevar a cabo la normalización vamos a emplear la función *MinMaxScaler* del módulo *preprocessing* de la librería *sklearn*. (sklearn es como se denota scikit-learn en Python)\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(df)\n",
    "\n",
    "Mostraremos algunos datos de nuestro data set.\n",
    "(Esta función nos dará error ¿Por qué? ¿Cómo solucionarlo?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-141548d4d57f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0marreglo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marreglo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "arreglo = preprocessing.LabelEncoder()\n",
    "df = df.apply(arreglo.fit_transform)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "\n",
    "df = pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "df.iloc[4:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis exploratorio de datos (Exploratory Data Analysis - EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Vamos a identificar las variables más significativas para predecir nuestra función. Para ello utilizaremos la función *SelectKBest* [info](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html) del sklearn. Utilizaremos el método predictivo chi2 para puntuar a cada una de ellas y seleccionaremos solo 3.\n",
    "\n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    X = df.loc[:,df.columns!='RainTomorrow']\n",
    "    y = df[['RainTomorrow']]\n",
    "    selector = SelectKBest(chi2, k=3)\n",
    "    selector.fit(X, y)\n",
    "    \n",
    "Y seleccionamos las variables con *get_support*.\n",
    "\n",
    "    print(X.columns[selector.get_support(indices=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Rainfall', 'Humidity3pm' y 'RainToday' son las variables más significativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construyendo un modelo de aprendizaje automático"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) En primer lugar, y para simplificar el modelo, vamos a emplear solo 'Humidity3pm' para construirlo. De esta forma tendremos 'Humidity3pm' como entrada y 'RainTomorrow' como salida. \n",
    "Crea una variable 'X' formada únicamente por la columna del *dataframe* 'Humidity3pm' y otra variable 'y' formada por la columna del *dataframe* 'RainTomorrow'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Vamos a construir modelos de clasificación utilizando los distintos algoritmos:\n",
    "- *Logistic regression* (Regresión logística) [info](https://en.wikipedia.org/wiki/Logistic_regression) \n",
    "- *Random Forest* (bosques aleatorios) [info](https://en.wikipedia.org/wiki/Random_forest) \n",
    "- *Decission Tree* (Árbol de decisión) [info](https://en.wikipedia.org/wiki/Decision_tree) \n",
    "- *Support Vector Machine* (Máquinas de vectores de soporte) [info](https://en.wikipedia.org/wiki/Support_vector_machine) \n",
    "\n",
    "\n",
    "No te preocupes si todavía no los conoces, profundizaremos sobre ellos a lo largo del curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.1) Logistic regression\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cargamos distintos recursos la librería sklearn. Concretamente necesitaremos el modelo de *logistic regression*, un método para obtener automáticamente los datos de entrenamiento y test, y otro método para obtener la precisión del modelo. \n",
    "\n",
    "\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dividimos los datos que tenemos en datos de entrenamiento o *training set* (conjunto de datos iniciales utilizados por el modelo para entender el problema y aprender sobre él) y datos de prueba o *test set* (conjunto de datos utilizados para comprobar lo que ha aprendido el modelo después de haber sido entrenado). __Nunca uses los datos de prueba para el entrenamiento o tus resultados estarían comprometidos__. Normalmente se utilzia un 80% de los datos para entrenamiento y un 20% para tests.\n",
    "\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construimos el modelo y lo entrenamos con el *training set*\n",
    "\n",
    "\n",
    "    clf_logreg = LogisticRegression(random_state=0)\n",
    "    clf_logreg.fit(X_train,y_train)\n",
    "\n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Evaluamos el modelo usando el *test set*.\n",
    "\n",
    "    y_pred = clf_logreg.predict(X_test)\n",
    "    score = accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por último mostramos por pantalla el *score* del modelo en %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.2) Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crea un modelo Random Forest [info](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    n_estimators=100, max_depth=4,random_state=0\n",
    "\n",
    "(Ignora el *warning*)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.3) Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crea un modelo Decision Tree [info](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    random_state=0    \n",
    "    \n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13.4) Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un modelo SVM, entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "    from sklearn import svm\n",
    "- Crea un modelo SVM [info](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html), entrénalo y evalúa el modelo siguiendo los pasos descritos en el punto 13.1)\n",
    "\n",
    "\n",
    "    from sklearn import svm\n",
    "    \n",
    "\n",
    "- Cuando construyas el modelo, utiliza los siguientes parámetros:\n",
    "\n",
    "\n",
    "    kernel='linear'\n",
    "    \n",
    "(Este modelo tarda en torno a 1 minuto en ejecutarse)\n",
    "(Ignora el *warning*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Ordena de mayor a menor precisión los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) ¿Con qué término en inglés se denota el sobreentrenamiento de un modelo de ML y qué características tiene?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
